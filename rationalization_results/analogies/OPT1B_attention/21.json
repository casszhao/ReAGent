{
    "$schema": "../docs/rationalization.schema.json",
    "id": 21,
    "input-text": [
        "</s>",
        "I",
        " knew",
        " it",
        " was",
        " high",
        ",",
        " but",
        " that",
        "'s",
        " before",
        " I",
        " saw",
        " it",
        " in",
        " person",
        ".",
        " (",
        "Just",
        " then",
        " I",
        " thought",
        " about",
        " my",
        " ex",
        "-",
        "wife",
        ",",
        " but",
        " I",
        " had",
        " to",
        " stop",
        " thinking",
        " about",
        " her",
        ").",
        " When",
        " I",
        " did",
        " end",
        " up",
        " seeing",
        " it",
        " in",
        " person",
        ",",
        " it",
        " was",
        " even"
    ],
    "input-tokens": [
        2,
        100,
        1467,
        24,
        21,
        239,
        6,
        53,
        14,
        18,
        137,
        38,
        794,
        24,
        11,
        621,
        4,
        36,
        6785,
        172,
        38,
        802,
        59,
        127,
        1931,
        12,
        12295,
        6,
        53,
        38,
        56,
        7,
        912,
        2053,
        59,
        69,
        322,
        520,
        38,
        222,
        253,
        62,
        1782,
        24,
        11,
        621,
        6,
        24,
        21,
        190
    ],
    "target-text": " higher",
    "target-token": 723,
    "rational-size": 5,
    "rational-positions": [
        0,
        48,
        36,
        46,
        49
    ],
    "rational-text": [
        "</s>",
        " was",
        ").",
        ",",
        " even"
    ],
    "rational-tokens": [
        2,
        21,
        322,
        6,
        190
    ],
    "importance-scores": [
        0.03417082875967026,
        0.019665639847517014,
        0.01963353343307972,
        0.019619347527623177,
        0.019621670246124268,
        0.01981794647872448,
        0.019945401698350906,
        0.019742010161280632,
        0.01964712329208851,
        0.019657166674733162,
        0.019679784774780273,
        0.019599927589297295,
        0.019603686407208443,
        0.0196305550634861,
        0.019638732075691223,
        0.019661378115415573,
        0.019975244998931885,
        0.01964939758181572,
        0.019600067287683487,
        0.019607871770858765,
        0.01959637925028801,
        0.019601164385676384,
        0.019621912389993668,
        0.019601022824645042,
        0.019604822620749474,
        0.019607892259955406,
        0.019597917795181274,
        0.01969185657799244,
        0.019658956676721573,
        0.01959802396595478,
        0.019598864018917084,
        0.01963748037815094,
        0.01960260234773159,
        0.0196024589240551,
        0.019615428522229195,
        0.01959695853292942,
        0.020100895315408707,
        0.019784288480877876,
        0.019650347530841827,
        0.01966332271695137,
        0.01964978687465191,
        0.019688338041305542,
        0.01974426582455635,
        0.019791966304183006,
        0.019742697477340698,
        0.019762182608246803,
        0.020097171887755394,
        0.019997650757431984,
        0.020294025540351868,
        0.020031994208693504
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "facebook/opt-1.3b",
            "cache_dir": "./cache/",
            "tokenizer": "facebook/opt-1.3b",
            "data_dir": "data/analogies/OPT1B/",
            "importance_results_dir": "rationalization_results/analogies/OPT1B_attention",
            "device": "cuda",
            "rationalization_config": "config/eva_attention.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/OPT1B_attention",
            "loglevel": 20
        },
        "time_elapsed": 0.022073745727539062
    }
}