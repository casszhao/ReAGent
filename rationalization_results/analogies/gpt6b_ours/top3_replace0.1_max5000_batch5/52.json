{
    "$schema": "../docs/rationalization.schema.json",
    "id": 52,
    "input-text": [
        "I",
        " really",
        " wanted",
        " to",
        " buy",
        " the",
        " pear",
        ",",
        " more",
        " than",
        " I",
        " ever",
        " wanted",
        " to",
        " buy",
        " anything",
        " before",
        ".",
        " (",
        "I",
        " was",
        " also",
        " behind",
        " on",
        " my",
        " homework",
        ",",
        " but",
        " that",
        "'s",
        " another",
        " story",
        ").",
        " So",
        " I",
        " went",
        " to",
        " the",
        " store",
        " and",
        " asked",
        " if",
        " they",
        " had",
        " any",
        " p"
    ],
    "input-tokens": [
        40,
        1107,
        2227,
        284,
        2822,
        262,
        25286,
        11,
        517,
        621,
        314,
        1683,
        2227,
        284,
        2822,
        1997,
        878,
        13,
        357,
        40,
        373,
        635,
        2157,
        319,
        616,
        26131,
        11,
        475,
        326,
        338,
        1194,
        1621,
        737,
        1406,
        314,
        1816,
        284,
        262,
        3650,
        290,
        1965,
        611,
        484,
        550,
        597,
        279
    ],
    "target-text": "ears",
    "target-token": 4127,
    "rational-size": 11,
    "rational-positions": [
        0,
        6,
        8,
        9,
        11,
        19,
        28,
        29,
        33,
        36,
        45
    ],
    "rational-text": [
        "I",
        " pear",
        " more",
        " than",
        " ever",
        "I",
        " that",
        "'s",
        " So",
        " to",
        " p"
    ],
    "rational-tokens": [
        40,
        25286,
        517,
        621,
        1683,
        40,
        326,
        338,
        1406,
        284,
        279
    ],
    "importance-scores": [
        0.036677949130535126,
        1.764090207245772e-09,
        2.0958281776728427e-09,
        1.2886491873587147e-09,
        1.5256633734139768e-09,
        1.4924050883990958e-09,
        0.062493156641721725,
        1.7013596087522842e-09,
        1.2557015427461238e-09,
        0.10149504989385605,
        1.2622509704129925e-09,
        0.1137186661362648,
        1.2966026030625244e-09,
        2.043746061275442e-09,
        2.116192554524332e-09,
        1.522000636633436e-09,
        1.5440978495817603e-09,
        0.06405288726091385,
        1.353676837290152e-09,
        1.5416657950240165e-09,
        1.569109953081238e-09,
        1.4318812802116554e-09,
        2.1362993596341084e-09,
        1.7961359066731575e-09,
        1.5887590132379614e-09,
        1.56021884301083e-09,
        1.4220393751429583e-09,
        1.5306650391622156e-09,
        3.11897063731692e-09,
        1.5962703381333654e-09,
        1.2107379543380148e-09,
        1.4454528685092782e-09,
        1.9451456001462475e-09,
        2.3482353839199277e-09,
        1.5404838515920005e-09,
        1.5475428716271722e-09,
        0.036866478621959686,
        1.4945730208992813e-09,
        1.4102280454508787e-09,
        1.2730316800713126e-09,
        1.4564948136452927e-09,
        1.717351261198985e-09,
        1.2315111153071712e-09,
        0.02957049384713173,
        1.5605822190067897e-09,
        0.5551252961158752
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "EleutherAI/gpt-j-6b",
            "cache_dir": "cache/",
            "tokenizer": "EleutherAI/gpt-j-6b",
            "data_dir": "data/analogies/gpt6b",
            "importance_results_dir": "rationalization_results/analogies/gpt6b_ours/top3_replace0.1_max5000_batch5",
            "device": "cuda",
            "rationalization_config": "config//top3_replace0.1_max5000_batch5.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/gpt6b_ours/top3_replace0.1_max5000_batch5",
            "loglevel": 20
        },
        "time_elapsed": 20.316951513290405,
        "separate_rational": [
            [
                " than",
                " to",
                "I",
                " p",
                " had",
                " pear",
                " ever",
                ","
            ],
            [
                " p",
                " more",
                " than",
                "'s",
                " that",
                "I",
                " asked",
                " pear"
            ],
            [
                ".",
                " than",
                " p",
                " pear",
                " wanted",
                " So",
                "I",
                " went"
            ],
            [
                " p",
                " that",
                "'s",
                " to",
                " ever",
                " more",
                "I",
                " on"
            ],
            [
                " ever",
                " p",
                " to",
                " pear",
                " So",
                " buy",
                " really",
                " behind"
            ]
        ]
    }
}