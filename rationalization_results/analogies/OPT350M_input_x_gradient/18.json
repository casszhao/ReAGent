{
    "$schema": "../docs/rationalization.schema.json",
    "id": 18,
    "input-text": [
        "</s>",
        "I",
        " had",
        " never",
        " been",
        " friends",
        " with",
        " any",
        " French",
        " people",
        " before",
        ".",
        " (",
        "The",
        " funn",
        "iest",
        " thing",
        " happened",
        " to",
        " me",
        " the",
        " other",
        " day",
        ",",
        " but",
        " that",
        "'s",
        " a",
        " story",
        " for",
        " another",
        " time",
        ").",
        " In",
        " fact",
        ",",
        " I",
        " had",
        " never",
        " even",
        " been",
        " to"
    ],
    "input-tokens": [
        2,
        100,
        56,
        393,
        57,
        964,
        19,
        143,
        1515,
        82,
        137,
        4,
        36,
        133,
        29310,
        7098,
        631,
        1102,
        7,
        162,
        5,
        97,
        183,
        6,
        53,
        14,
        18,
        10,
        527,
        13,
        277,
        86,
        322,
        96,
        754,
        6,
        38,
        56,
        393,
        190,
        57,
        7
    ],
    "target-text": " France",
    "target-token": 1470,
    "rational-size": 5,
    "rational-positions": [
        9,
        1,
        41,
        40,
        6
    ],
    "rational-text": [
        " people",
        "I",
        " to",
        " been",
        " with"
    ],
    "rational-tokens": [
        82,
        100,
        7,
        57,
        19
    ],
    "importance-scores": [
        0.03154546022415161,
        0.05601825192570686,
        0.021569479256868362,
        0.027508364990353584,
        0.02978644333779812,
        0.02038685791194439,
        0.046222023665905,
        0.03984960913658142,
        0.02352980710566044,
        0.12313065677881241,
        0.03537244722247124,
        0.016749413684010506,
        0.017860999330878258,
        0.013557353988289833,
        0.005279202479869127,
        0.014486409723758698,
        0.007576564326882362,
        0.006762929726392031,
        0.011634096503257751,
        0.008365592919290066,
        0.007523089647293091,
        0.009703141637146473,
        0.006188804749399424,
        0.009911792352795601,
        0.008322813548147678,
        0.005577833857387304,
        0.004986689891666174,
        0.004762783646583557,
        0.006442449986934662,
        0.0071004219353199005,
        0.0055424487218260765,
        0.005055432673543692,
        0.005706803407520056,
        0.021199805662035942,
        0.015574555844068527,
        0.036929529160261154,
        0.02393149584531784,
        0.01799405738711357,
        0.021602539345622063,
        0.04002987965941429,
        0.05111857131123543,
        0.05381283909082413
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "facebook/opt-350m",
            "cache_dir": "./cache/",
            "tokenizer": "facebook/opt-350m",
            "data_dir": "data/analogies/OPT350M/",
            "importance_results_dir": "rationalization_results/analogies/OPT350M_input_x_gradient",
            "device": "cuda",
            "rationalization_config": "config/eva_input_x_gradient.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/OPT350M_input_x_gradient",
            "loglevel": 20
        },
        "time_elapsed": 0.03959774971008301
    }
}