{
    "$schema": "../docs/rationalization.schema.json",
    "id": 26,
    "input-text": [
        "As",
        " soon",
        " as",
        " I",
        " arrived",
        " in",
        " Hungary",
        ",",
        " I",
        " checked",
        " into",
        " my",
        " hotel",
        " and",
        " took",
        " a",
        " long",
        " nap",
        ".",
        " (",
        "I",
        " had",
        " finally",
        " finished",
        " the",
        " book",
        " I",
        " was",
        " reading",
        " and",
        " it",
        " was",
        " amazing",
        ").",
        " I",
        " had",
        " to",
        " figure",
        " out",
        " the",
        " exchange",
        " rate",
        " to",
        " the",
        " local",
        " currency",
        ",",
        " which",
        " is",
        " apparently",
        " called",
        " the",
        " for"
    ],
    "input-tokens": [
        1722,
        2582,
        355,
        314,
        5284,
        287,
        19562,
        11,
        314,
        10667,
        656,
        616,
        7541,
        290,
        1718,
        257,
        890,
        25422,
        13,
        357,
        40,
        550,
        3443,
        5201,
        262,
        1492,
        314,
        373,
        3555,
        290,
        340,
        373,
        4998,
        737,
        314,
        550,
        284,
        3785,
        503,
        262,
        5163,
        2494,
        284,
        262,
        1957,
        7395,
        11,
        543,
        318,
        5729,
        1444,
        262,
        329
    ],
    "target-text": "int",
    "target-token": 600,
    "rational-size": 5,
    "rational-positions": [
        51,
        45,
        50,
        52,
        6
    ],
    "rational-text": [
        " the",
        " currency",
        " called",
        " for",
        " Hungary"
    ],
    "rational-tokens": [
        262,
        7395,
        1444,
        329,
        19562
    ],
    "importance-scores": [
        0.025520648807287216,
        0.008615467697381973,
        0.0071791838854551315,
        0.008802040480077267,
        0.013913596980273724,
        0.012803707271814346,
        0.04566100239753723,
        0.00713948393240571,
        0.002894326578825712,
        0.010652056895196438,
        0.00818532332777977,
        0.0056467982940375805,
        0.0060590417124331,
        0.001836160197854042,
        0.0028556743636727333,
        0.0030504444148391485,
        0.001876596943475306,
        0.006945772096514702,
        0.005884881131350994,
        0.004741269629448652,
        0.0024365349672734737,
        0.00424798671156168,
        0.00641857273876667,
        0.006185884587466717,
        0.00588733796030283,
        0.009442116133868694,
        0.0027527455240488052,
        0.006016331724822521,
        0.004210853483527899,
        0.0028637435752898455,
        0.0029970987234264612,
        0.004886840935796499,
        0.007267434149980545,
        0.014839048497378826,
        0.007688481360673904,
        0.006922530941665173,
        0.003540268400683999,
        0.007078274618834257,
        0.013499879278242588,
        0.007411631755530834,
        0.02475990727543831,
        0.04502338916063309,
        0.008368161506950855,
        0.017936715856194496,
        0.023504601791501045,
        0.11746266484260559,
        0.006119200959801674,
        0.019093593582510948,
        0.01939067803323269,
        0.021432779729366302,
        0.1121690422296524,
        0.183865025639534,
        0.08401714265346527
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "EleutherAI/gpt-j-6b",
            "cache_dir": "./cache/",
            "tokenizer": "EleutherAI/gpt-j-6b",
            "data_dir": "data/analogies/gpt6b/",
            "importance_results_dir": "rationalization_results/analogies/gpt6b_input_x_gradient",
            "device": "cuda",
            "rationalization_config": "config/eva_input_x_gradient.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/gpt6b_input_x_gradient",
            "loglevel": 20
        },
        "time_elapsed": 0.17647409439086914
    }
}