{
    "$schema": "../docs/rationalization.schema.json",
    "id": 32,
    "input-text": [
        "I",
        " initially",
        " invited",
        " my",
        " step",
        "father",
        ",",
        " who",
        " gladly",
        " accepted",
        " my",
        " invitation",
        ".",
        " (",
        "My",
        " favorite",
        " song",
        " just",
        " came",
        " on",
        ",",
        " so",
        " I",
        " was",
        " able",
        " to",
        " relax",
        ").",
        " When",
        " I",
        " learned",
        " that",
        " women",
        " were",
        " allowed",
        ",",
        " I",
        " went",
        " ahead",
        " and",
        " also",
        " invited",
        " my",
        " step"
    ],
    "input-tokens": [
        40,
        7317,
        9392,
        616,
        2239,
        11358,
        11,
        508,
        35092,
        6292,
        616,
        17023,
        13,
        357,
        3666,
        4004,
        3496,
        655,
        1625,
        319,
        11,
        523,
        314,
        373,
        1498,
        284,
        8960,
        737,
        1649,
        314,
        4499,
        326,
        1466,
        547,
        3142,
        11,
        314,
        1816,
        4058,
        290,
        635,
        9392,
        616,
        2239
    ],
    "target-text": "mother",
    "target-token": 13552,
    "rational-size": 5,
    "rational-positions": [
        43,
        5,
        42,
        40,
        16
    ],
    "rational-text": [
        " step",
        "father",
        " my",
        " also",
        " song"
    ],
    "rational-tokens": [
        2239,
        11358,
        616,
        635,
        3496
    ],
    "importance-scores": [
        5.912502729188418e-06,
        0.01160838920623064,
        0.006294343154877424,
        0.0039449953474104404,
        0.004597919527441263,
        0.06331964582204819,
        0.0001546355488244444,
        0.006381491664797068,
        0.011011979542672634,
        0.008644918911159039,
        0.006100968457758427,
        0.00798647478222847,
        0.0012103910557925701,
        0.003412507241591811,
        0.008499749936163425,
        0.009746294468641281,
        0.012138675898313522,
        0.008547421544790268,
        0.006748685147613287,
        0.003334578825160861,
        0.003151790937408805,
        0.006239195354282856,
        0.00630400562658906,
        0.006758611183613539,
        0.007884383201599121,
        0.00491225766018033,
        0.006725032813847065,
        0.009793336503207684,
        0.009067420847713947,
        0.01083085872232914,
        0.008115985430777073,
        0.009488372132182121,
        0.009845441207289696,
        0.00816345401108265,
        0.0072130560874938965,
        0.003507627174258232,
        0.0070001003332436085,
        0.006988220848143101,
        0.005398217123001814,
        0.007963054813444614,
        0.017963159829378128,
        0.005103997886180878,
        0.03325895965099335,
        0.6146333813667297
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "EleutherAI/gpt-j-6b",
            "cache_dir": "./cache/",
            "tokenizer": "EleutherAI/gpt-j-6b",
            "data_dir": "data/analogies/gpt6b/",
            "importance_results_dir": "rationalization_results/analogies/gpt6b_integrated_gradients",
            "device": "cuda",
            "rationalization_config": "config/eva_integrated_gradients.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/gpt6b_integrated_gradients",
            "loglevel": 20
        },
        "time_elapsed": 14.628076791763306
    }
}