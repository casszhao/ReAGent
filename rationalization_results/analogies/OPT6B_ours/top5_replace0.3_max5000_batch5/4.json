{
    "$schema": "../docs/rationalization.schema.json",
    "id": 4,
    "input-text": [
        "</s>",
        "As",
        " soon",
        " as",
        " I",
        " arrived",
        " in",
        " Iran",
        ",",
        " I",
        " checked",
        " into",
        " my",
        " hotel",
        " and",
        " took",
        " a",
        " long",
        " nap",
        ".",
        " (",
        "I",
        " had",
        " finally",
        " finished",
        " the",
        " book",
        " I",
        " was",
        " reading",
        " and",
        " it",
        " was",
        " amazing",
        ").",
        " I",
        " had",
        " to",
        " figure",
        " out",
        " the",
        " exchange",
        " rate",
        " to",
        " the",
        " local",
        " currency",
        ",",
        " which",
        " is",
        " apparently",
        " called",
        " the",
        " r"
    ],
    "input-tokens": [
        2,
        1620,
        1010,
        25,
        38,
        2035,
        11,
        1603,
        6,
        38,
        7869,
        88,
        127,
        2303,
        8,
        362,
        10,
        251,
        16159,
        4,
        36,
        100,
        56,
        1747,
        1550,
        5,
        1040,
        38,
        21,
        2600,
        8,
        24,
        21,
        2770,
        322,
        38,
        56,
        7,
        1955,
        66,
        5,
        2081,
        731,
        7,
        5,
        400,
        2593,
        6,
        61,
        16,
        4100,
        373,
        5,
        910
    ],
    "target-text": "ial",
    "target-token": 2617,
    "rational-size": 9,
    "rational-positions": [
        5,
        6,
        10,
        20,
        39,
        46,
        51,
        52,
        53
    ],
    "rational-text": [
        " arrived",
        " in",
        " checked",
        " (",
        " out",
        " currency",
        " called",
        " the",
        " r"
    ],
    "rational-tokens": [
        2035,
        11,
        7869,
        36,
        66,
        2593,
        373,
        5,
        910
    ],
    "importance-scores": [
        4.178011536737358e-08,
        1.3807481824557044e-09,
        2.9180116101201747e-09,
        8.801818829340391e-09,
        6.799487639597146e-10,
        4.3503514679521516e-10,
        4.362063066309929e-07,
        4.839488383368007e-07,
        1.0240891044867038e-16,
        1.1557492598512908e-06,
        0.26024723052978516,
        5.5570426732431955e-11,
        0.22002406418323517,
        4.6257112994597255e-14,
        1.1504325053354747e-12,
        4.65850827965214e-13,
        4.5620513446920086e-06,
        8.690977892911178e-08,
        1.859971551776418e-11,
        0.012663718312978745,
        0.00012799142859876156,
        1.4291226283435175e-14,
        3.173611005068133e-13,
        3.304636841949815e-10,
        4.5626514719177e-12,
        6.938944419054849e-10,
        6.723166023903104e-08,
        1.0327627880410368e-17,
        1.300336921472578e-10,
        5.945089120431776e-14,
        7.509029509300547e-10,
        1.124831396737136e-05,
        2.693512669793563e-06,
        2.5824216029479707e-11,
        9.125576542253627e-14,
        1.9195546541173059e-10,
        5.386364843192569e-14,
        4.609072184243862e-15,
        2.4150545075881426e-18,
        2.798024398981136e-12,
        0.0011333406437188387,
        5.928113999686957e-09,
        4.847316666979629e-13,
        1.0027507253360102e-12,
        5.854707994454311e-13,
        0.005523093976080418,
        0.0005398064386099577,
        1.9949762645410374e-05,
        2.056770959059026e-13,
        3.63626818839994e-18,
        8.673784464008349e-07,
        2.301107542734826e-06,
        0.2496722936630249,
        0.25002455711364746
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "KoboldAI/OPT-6.7B-Erebus",
            "cache_dir": "cache/",
            "tokenizer": "KoboldAI/OPT-6.7B-Erebus",
            "data_dir": "data/analogies/OPT6B/",
            "importance_results_dir": "rationalization_results/analogies/OPT6B_ours/top5_replace0.3_max5000_batch5",
            "device": "cuda",
            "rationalization_config": "config/OPT6B/top5_replace0.3_max5000_batch5.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/OPT6B_ours/top5_replace0.3_max5000_batch5",
            "loglevel": 20
        },
        "time_elapsed": 2711.8243973255157,
        "separate_rational": [
            [
                " my",
                ".",
                " checked",
                " local",
                " was",
                " called",
                " I",
                " in"
            ],
            [
                " r",
                "</s>",
                "As",
                " soon",
                " as",
                " I",
                " arrived",
                " in"
            ],
            [
                " r",
                " arrived",
                " out",
                " called",
                " currency",
                " amazing",
                " in",
                " ("
            ],
            [
                " checked",
                " the",
                " the",
                " (",
                ",",
                " it",
                " a",
                " apparently"
            ],
            [
                " the",
                " currency",
                " r",
                " the",
                " checked",
                " (",
                " Iran",
                " out"
            ]
        ]
    }
}