{
    "$schema": "../docs/rationalization.schema.json",
    "id": 13,
    "input-text": [
        "</s>",
        "I",
        " knew",
        " it",
        " was",
        " low",
        ",",
        " but",
        " that",
        "'s",
        " before",
        " I",
        " saw",
        " it",
        " in",
        " person",
        ".",
        " (",
        "Just",
        " then",
        " I",
        " thought",
        " about",
        " my",
        " ex",
        "-",
        "wife",
        ",",
        " but",
        " I",
        " had",
        " to",
        " stop",
        " thinking",
        " about",
        " her",
        ").",
        " When",
        " I",
        " did",
        " end",
        " up",
        " seeing",
        " it",
        " in",
        " person",
        ",",
        " it",
        " was",
        " even"
    ],
    "input-tokens": [
        2,
        100,
        1467,
        24,
        21,
        614,
        6,
        53,
        14,
        18,
        137,
        38,
        794,
        24,
        11,
        621,
        4,
        36,
        6785,
        172,
        38,
        802,
        59,
        127,
        1931,
        12,
        12295,
        6,
        53,
        38,
        56,
        7,
        912,
        2053,
        59,
        69,
        322,
        520,
        38,
        222,
        253,
        62,
        1782,
        24,
        11,
        621,
        6,
        24,
        21,
        190
    ],
    "target-text": " lower",
    "target-token": 795,
    "rational-size": 11,
    "rational-positions": [
        1,
        2,
        4,
        5,
        7,
        23,
        37,
        40,
        47,
        48,
        49
    ],
    "rational-text": [
        "I",
        " knew",
        " was",
        " low",
        " but",
        " my",
        " When",
        " end",
        " it",
        " was",
        " even"
    ],
    "rational-tokens": [
        100,
        1467,
        21,
        614,
        53,
        127,
        520,
        253,
        24,
        21,
        190
    ],
    "importance-scores": [
        1.4735217071200053e-19,
        0.20000000298023224,
        0.19680732488632202,
        8.569364722959645e-35,
        0.19856026768684387,
        0.20000000298023224,
        9.352309185090535e-21,
        8.359010372771536e-09,
        5.42928094599638e-25,
        1.2863468535285596e-30,
        3.5084850584614225e-31,
        5.646863222903235e-19,
        1.0617725077854042e-20,
        6.630659143796981e-16,
        4.4089813180589466e-13,
        4.6223419248182785e-18,
        2.586234686423241e-15,
        1.8072891991576133e-29,
        9.728776565801813e-27,
        5.889090340274965e-31,
        9.984939115100914e-26,
        0.20000000298023224,
        2.8360718042911233e-25,
        6.024261771761624e-17,
        6.580944878993097e-33,
        1.7227982685190033e-14,
        1.2396144169356158e-18,
        1.9870709972023606e-36,
        2.5900515972089423e-18,
        2.5348931317679042e-23,
        1.917681409973954e-20,
        1.565704405353262e-39,
        4.0184388921386335e-20,
        1.5953543284213278e-20,
        1.269267943291197e-32,
        9.955241419803209e-29,
        6.160812160117257e-30,
        8.016722008452604e-11,
        5.2586514875622605e-33,
        3.032671448086619e-15,
        1.3201906767790206e-05,
        5.766904285275353e-31,
        8.578284048077673e-32,
        1.6261919585989874e-14,
        2.0135632060832964e-36,
        1.8995575987654065e-37,
        2.0932642198465993e-36,
        0.0031432658433914185,
        1.3517996242903838e-19,
        0.0014759220648556948
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "KoboldAI/OPT-6.7B-Erebus",
            "cache_dir": "cache/",
            "tokenizer": "KoboldAI/OPT-6.7B-Erebus",
            "data_dir": "data/analogies/OPT6B/",
            "importance_results_dir": "rationalization_results/analogies/OPT6B_ours/top5_replace0.3_max5000_batch5",
            "device": "cuda",
            "rationalization_config": "config/OPT6B/top5_replace0.3_max5000_batch5.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/OPT6B_ours/top5_replace0.3_max5000_batch5",
            "loglevel": 20
        },
        "time_elapsed": 1723.828932762146,
        "separate_rational": [
            [
                " thought",
                " even",
                " was",
                " low",
                " my",
                " it",
                " saw",
                "Just"
            ],
            [
                "I",
                " low",
                " When",
                " was",
                " even",
                " end",
                " that",
                " was"
            ],
            [
                " was",
                " even",
                " was",
                " I",
                " my",
                " but",
                " low",
                " knew"
            ],
            [
                " knew",
                " it",
                " even",
                " end",
                " but",
                " When",
                " was",
                " low"
            ],
            [
                " low",
                " When",
                "I",
                "'s",
                " even",
                " about",
                " was",
                " it"
            ]
        ]
    }
}