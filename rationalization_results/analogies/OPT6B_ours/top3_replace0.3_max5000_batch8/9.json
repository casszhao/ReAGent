{
    "$schema": "../docs/rationalization.schema.json",
    "id": 9,
    "input-text": [
        "</s>",
        "I",
        " initially",
        " invited",
        " my",
        " dad",
        ",",
        " who",
        " gladly",
        " accepted",
        " my",
        " invitation",
        ".",
        " (",
        "My",
        " favorite",
        " song",
        " just",
        " came",
        " on",
        ",",
        " so",
        " I",
        " was",
        " able",
        " to",
        " relax",
        ").",
        " When",
        " I",
        " learned",
        " that",
        " women",
        " were",
        " allowed",
        ",",
        " I",
        " went",
        " ahead",
        " and",
        " also",
        " invited",
        " my"
    ],
    "input-tokens": [
        2,
        100,
        3225,
        4036,
        127,
        4252,
        6,
        54,
        36811,
        3903,
        127,
        10021,
        4,
        36,
        2387,
        2674,
        2214,
        95,
        376,
        15,
        6,
        98,
        38,
        21,
        441,
        7,
        12327,
        322,
        520,
        38,
        2435,
        14,
        390,
        58,
        1220,
        6,
        38,
        439,
        789,
        8,
        67,
        4036,
        127
    ],
    "target-text": " mom",
    "target-token": 3795,
    "rational-size": 19,
    "rational-positions": [
        1,
        5,
        9,
        11,
        12,
        14,
        21,
        22,
        24,
        27,
        28,
        29,
        31,
        32,
        35,
        37,
        39,
        40,
        42
    ],
    "rational-text": [
        "I",
        " dad",
        " accepted",
        " invitation",
        ".",
        "My",
        " so",
        " I",
        " able",
        ").",
        " When",
        " I",
        " that",
        " women",
        ",",
        " went",
        " and",
        " also",
        " my"
    ],
    "rational-tokens": [
        100,
        4252,
        3903,
        10021,
        4,
        2387,
        98,
        38,
        441,
        322,
        520,
        38,
        14,
        390,
        6,
        439,
        8,
        67,
        127
    ],
    "importance-scores": [
        0.002727911341935396,
        0.1287488043308258,
        0.012412767857313156,
        0.06496935337781906,
        0.0018556448630988598,
        0.07828881591558456,
        0.0010011042468249798,
        0.0011456954525783658,
        0.0005564808961935341,
        0.15813623368740082,
        0.00141991232521832,
        0.04002458602190018,
        0.0010849691461771727,
        0.006253723055124283,
        0.010199049487709999,
        0.0020361251663416624,
        0.001008430728688836,
        0.00012953419354744256,
        0.04517636075615883,
        0.0011530121555551887,
        0.01077447272837162,
        0.01073260698467493,
        0.008093567565083504,
        0.0015142386546358466,
        0.005720081739127636,
        0.0021799462847411633,
        0.0007460267515853047,
        0.1980603039264679,
        0.01072377897799015,
        0.056904762983322144,
        0.008554719388484955,
        0.017999161034822464,
        0.019573263823986053,
        0.021178267896175385,
        0.0009805592708289623,
        0.0031268014572560787,
        0.004995298106223345,
        0.0014642976457253098,
        0.010033104568719864,
        0.03115225024521351,
        0.005946724209934473,
        0.00377080705948174,
        0.0074464669451117516
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "KoboldAI/OPT-6.7B-Erebus",
            "cache_dir": "cache/",
            "tokenizer": "KoboldAI/OPT-6.7B-Erebus",
            "data_dir": "data/analogies/OPT6B/",
            "importance_results_dir": "rationalization_results/analogies/OPT6B_ours/top3_replace0.3_max5000_batch8",
            "device": "cuda",
            "rationalization_config": "config/OPT6B/top3_replace0.3_max5000_batch8.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/OPT6B_ours/top3_replace0.3_max5000_batch8",
            "loglevel": 20
        },
        "time_elapsed": 192.94214987754822,
        "separate_rational": [
            [
                " invited",
                " were",
                " that",
                " dad",
                " and",
                " so",
                " (",
                " invited"
            ],
            [
                " dad",
                " came",
                " ahead",
                ",",
                " that",
                " learned",
                ",",
                " I"
            ],
            [
                "I",
                " accepted",
                " went",
                " my",
                ".",
                " dad",
                " also",
                " When"
            ],
            [
                " I",
                " women",
                " so",
                " and",
                " my",
                " I",
                "I",
                " dad"
            ],
            [
                " accepted",
                " invitation",
                " initially",
                " When",
                " able",
                " dad",
                ",",
                ","
            ],
            [
                ").",
                " dad",
                " women",
                "I",
                " I",
                " that",
                "My",
                " so"
            ],
            [
                " accepted",
                " and",
                "My",
                " also",
                ").",
                " my",
                ".",
                " gladly"
            ],
            [
                ").",
                " my",
                " invitation",
                " able",
                " went",
                "</s>",
                " When",
                " and"
            ]
        ]
    }
}