{
    "$schema": "../docs/rationalization.schema.json",
    "id": 136,
    "input-text": [
        "I",
        " had",
        " never",
        " been",
        " friends",
        " with",
        " any",
        " Korean",
        " people",
        " before",
        ".",
        " (",
        "The",
        " funn",
        "iest",
        " thing",
        " happened",
        " to",
        " me",
        " the",
        " other",
        " day",
        ",",
        " but",
        " that",
        "'s",
        " a",
        " story",
        " for",
        " another",
        " time",
        ").",
        " In",
        " fact",
        ",",
        " I",
        " had",
        " never",
        " even",
        " been",
        " to"
    ],
    "input-tokens": [
        40,
        550,
        1239,
        587,
        2460,
        351,
        597,
        6983,
        661,
        878,
        13,
        357,
        464,
        36090,
        6386,
        1517,
        3022,
        284,
        502,
        262,
        584,
        1110,
        11,
        475,
        326,
        338,
        257,
        1621,
        329,
        1194,
        640,
        737,
        554,
        1109,
        11,
        314,
        550,
        1239,
        772,
        587,
        284
    ],
    "target-text": " Korea",
    "target-token": 4969,
    "rational-size": 5,
    "rational-positions": [
        39,
        10,
        7,
        38,
        40
    ],
    "rational-text": [
        " been",
        ".",
        " Korean",
        " even",
        " to"
    ],
    "rational-tokens": [
        587,
        13,
        6983,
        772,
        284
    ],
    "importance-scores": [
        0.016634304076433182,
        0.014964873902499676,
        0.012661883607506752,
        0.010949915274977684,
        0.01927633211016655,
        0.019674153998494148,
        0.012576069682836533,
        0.07889687269926071,
        0.016253376379609108,
        0.012010295875370502,
        0.08174266666173935,
        0.03094184584915638,
        0.013296783901751041,
        0.017715370282530785,
        0.011719012632966042,
        0.009750463999807835,
        0.012094873003661633,
        0.018689246848225594,
        0.009936342015862465,
        0.02644442208111286,
        0.008366025052964687,
        0.012285935692489147,
        0.02529793791472912,
        0.008939526975154877,
        0.012415682896971703,
        0.014000354334712029,
        0.021357443183660507,
        0.012421824969351292,
        0.014209466986358166,
        0.00850130058825016,
        0.010058167390525341,
        0.017839817330241203,
        0.02296268753707409,
        0.02260316163301468,
        0.023664111271500587,
        0.011410648003220558,
        0.014307773672044277,
        0.03654995188117027,
        0.07526398450136185,
        0.13986800611019135,
        0.041447047144174576
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "gpt2-medium",
            "cache_dir": "./cache/",
            "tokenizer": "gpt2-medium",
            "data_dir": "data/analogies/gpt2/",
            "importance_results_dir": "rationalization_results/analogies/gpt2_integrated_gradients",
            "device": "cuda",
            "rationalization_config": "config/eva_integrated_gradients.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/gpt2_integrated_gradients",
            "loglevel": 20
        },
        "time_elapsed": 0.30469369888305664
    }
}