{
    "$schema": "../docs/rationalization.schema.json",
    "id": 13,
    "input-text": [
        "When",
        " my",
        " flight",
        " landed",
        " in",
        " Russia",
        ",",
        " I",
        " converted",
        " my",
        " currency",
        " and",
        " slowly",
        " fell",
        " asleep",
        ".",
        " (",
        "I",
        " had",
        " a",
        " terrifying",
        " dream",
        " about",
        " my",
        " grandmother",
        ",",
        " but",
        " that",
        "'s",
        " a",
        " story",
        " for",
        " another",
        " time",
        ").",
        " I",
        " was",
        " staying",
        " in",
        " the",
        " capital",
        ","
    ],
    "input-tokens": [
        2215,
        616,
        5474,
        11406,
        287,
        3284,
        11,
        314,
        11513,
        616,
        7395,
        290,
        6364,
        3214,
        16039,
        13,
        357,
        40,
        550,
        257,
        17623,
        4320,
        546,
        616,
        18410,
        11,
        475,
        326,
        338,
        257,
        1621,
        329,
        1194,
        640,
        737,
        314,
        373,
        10589,
        287,
        262,
        3139,
        11
    ],
    "target-text": " Moscow",
    "target-token": 9070,
    "rational-size": 5,
    "rational-positions": [
        41,
        40,
        5,
        38,
        10
    ],
    "rational-text": [
        ",",
        " capital",
        " Russia",
        " in",
        " currency"
    ],
    "rational-tokens": [
        11,
        3139,
        3284,
        287,
        7395
    ],
    "importance-scores": [
        6.5870722662038234e-21,
        4.1952702289183754e-18,
        1.1748849745508212e-30,
        1.5436464928488138e-20,
        2.644970472446242e-29,
        2.0726184857267071e-07,
        1.25541777321249e-25,
        1.75518250649688e-13,
        7.114932148578e-30,
        9.6818594948721e-25,
        1.0596599153700481e-08,
        7.228448030336794e-27,
        7.977867717002789e-22,
        3.0521788253824856e-22,
        9.754963503638692e-11,
        1.1039262491381716e-36,
        3.70934928532627e-20,
        3.0839700495319036e-27,
        4.688446375634528e-36,
        5.931098093780809e-27,
        1.5029969611949633e-25,
        4.4635699829127065e-21,
        6.713844941800369e-27,
        8.851608780006434e-36,
        1.7596848329761483e-31,
        3.604473576160869e-31,
        1.4256346746248997e-38,
        1.5124767213449576e-16,
        3.9010414439382994e-30,
        1.8450345390534775e-31,
        3.780434992828319e-11,
        4.151259723343767e-22,
        1.8736197310750788e-29,
        7.398570645023028e-11,
        1.9067700950706914e-17,
        7.735774877387549e-15,
        2.0434344494280055e-10,
        1.3895187084278504e-12,
        2.6799670038712975e-08,
        6.090231942888769e-14,
        4.0552660607318103e-07,
        0.9999992847442627
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "gpt2-medium",
            "tokenizer": "gpt2-medium",
            "data_dir": "data/analogies",
            "output_dir": "rationalization_results/analogies/gpt2-medium.sampling.uniform",
            "device": "cuda",
            "rationalization_config": "config/test2.json",
            "input_data_size": 1,
            "logfile": "logs/analogies/gpt2-medium.sampling.uniform/test.log",
            "loglevel": 20
        },
        "time_elapsed": 61.94110345840454
    }
}