{
    "$schema": "../docs/rationalization.schema.json",
    "id": 148,
    "input-text": [
        "Although",
        " I",
        " sang",
        " yesterday",
        ",",
        " I",
        " had",
        " a",
        " million",
        " things",
        " to",
        " do",
        " today",
        ".",
        " (",
        "I",
        " suddenly",
        " felt",
        " a",
        " pin",
        "ched",
        " nerve",
        ",",
        " so",
        " I",
        " made",
        " a",
        " mental",
        " note",
        " to",
        " get",
        " that",
        " checked",
        " out",
        ").",
        " So",
        " today",
        " I",
        " wouldn",
        "'t",
        " have",
        " time",
        " to",
        " do",
        " any",
        " more"
    ],
    "input-tokens": [
        7003,
        314,
        25889,
        7415,
        11,
        314,
        550,
        257,
        1510,
        1243,
        284,
        466,
        1909,
        13,
        357,
        40,
        6451,
        2936,
        257,
        6757,
        1740,
        16384,
        11,
        523,
        314,
        925,
        257,
        5110,
        3465,
        284,
        651,
        326,
        10667,
        503,
        737,
        1406,
        1909,
        314,
        3636,
        470,
        423,
        640,
        284,
        466,
        597,
        517
    ],
    "target-text": " singing",
    "target-token": 13777,
    "rational-size": 5,
    "rational-positions": [
        4,
        2,
        13,
        0,
        1
    ],
    "rational-text": [
        ",",
        " sang",
        ".",
        "Although",
        " I"
    ],
    "rational-tokens": [
        11,
        25889,
        13,
        7003,
        314
    ],
    "importance-scores": [
        0.07979408651590347,
        0.06170983612537384,
        0.1572718471288681,
        0.04632304608821869,
        0.19260138273239136,
        0.01024253573268652,
        0.009024233557283878,
        0.0213761143386364,
        0.021361593157052994,
        0.012036589905619621,
        0.011044610291719437,
        0.005914987996220589,
        0.0165079515427351,
        0.08113345503807068,
        0.015661323443055153,
        0.005391491577029228,
        0.011947507970035076,
        0.006106716115027666,
        0.004310711286962032,
        0.012199115008115768,
        0.00801392924040556,
        0.022816069424152374,
        0.017694249749183655,
        0.003303298493847251,
        0.0035612869542092085,
        0.004142166115343571,
        0.0030309786088764668,
        0.010323859751224518,
        0.008542964234948158,
        0.0020430968143045902,
        0.002907358342781663,
        0.004578834865242243,
        0.00985464733093977,
        0.0026223293971270323,
        0.014316382817924023,
        0.0066618360579013824,
        0.011558091267943382,
        0.0033868560567498207,
        0.01361511368304491,
        0.004776952788233757,
        0.0032398479524999857,
        0.01052261795848608,
        0.003109552664682269,
        0.01140857208520174,
        0.006604750175029039,
        0.025405200198292732
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "gpt2-medium",
            "cache_dir": "cache/",
            "tokenizer": "gpt2-medium",
            "data_dir": "data/analogies/gpt2/",
            "importance_results_dir": "rationalization_results/analogies/gpt2_inseq_ig",
            "device": "cuda",
            "rationalization_config": "config/eva_inseq_ig.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/gpt2_inseq_ig",
            "loglevel": 20
        },
        "time_elapsed": 0.11774349212646484
    }
}