{
    "$schema": "../docs/rationalization.schema.json",
    "id": 27,
    "input-text": [
        "As",
        " soon",
        " as",
        " I",
        " arrived",
        " in",
        " Latvia",
        ",",
        " I",
        " checked",
        " into",
        " my",
        " hotel",
        " and",
        " took",
        " a",
        " long",
        " nap",
        ".",
        " (",
        "I",
        " had",
        " finally",
        " finished",
        " the",
        " book",
        " I",
        " was",
        " reading",
        " and",
        " it",
        " was",
        " amazing",
        ").",
        " I",
        " had",
        " to",
        " figure",
        " out",
        " the",
        " exchange",
        " rate",
        " to",
        " the",
        " local",
        " currency",
        ",",
        " which",
        " is",
        " apparently",
        " called",
        " the",
        " l"
    ],
    "input-tokens": [
        1722,
        2582,
        355,
        314,
        5284,
        287,
        35794,
        11,
        314,
        10667,
        656,
        616,
        7541,
        290,
        1718,
        257,
        890,
        25422,
        13,
        357,
        40,
        550,
        3443,
        5201,
        262,
        1492,
        314,
        373,
        3555,
        290,
        340,
        373,
        4998,
        737,
        314,
        550,
        284,
        3785,
        503,
        262,
        5163,
        2494,
        284,
        262,
        1957,
        7395,
        11,
        543,
        318,
        5729,
        1444,
        262,
        300
    ],
    "target-text": "ats",
    "target-token": 1381,
    "rational-size": 5,
    "rational-positions": [
        6,
        52,
        5,
        40,
        51
    ],
    "rational-text": [
        " Latvia",
        " l",
        " in",
        " exchange",
        " the"
    ],
    "rational-tokens": [
        35794,
        300,
        287,
        5163,
        262
    ],
    "importance-scores": [
        0.019086677581071854,
        0.01890224777162075,
        0.0189980436116457,
        0.01906060054898262,
        0.019352763891220093,
        0.019675634801387787,
        0.024098752066493034,
        0.01855563558638096,
        0.018458014354109764,
        0.01853972300887108,
        0.018460100516676903,
        0.018540607765316963,
        0.018639668822288513,
        0.018480783328413963,
        0.018453488126397133,
        0.018464580178260803,
        0.018425097689032555,
        0.01863705739378929,
        0.018626743927598,
        0.01854066550731659,
        0.0184334609657526,
        0.018440328538417816,
        0.01845834217965603,
        0.01850876212120056,
        0.01850472018122673,
        0.01861286535859108,
        0.01843435689806938,
        0.01846161298453808,
        0.01849108189344406,
        0.01849740743637085,
        0.01844024658203125,
        0.018484830856323242,
        0.018610306084156036,
        0.01866874285042286,
        0.01849808730185032,
        0.018577879294753075,
        0.018579762428998947,
        0.018748916685581207,
        0.018596651032567024,
        0.018733255565166473,
        0.019671354442834854,
        0.01908685825765133,
        0.01870507001876831,
        0.01875680312514305,
        0.01918599382042885,
        0.019517360255122185,
        0.018724311143159866,
        0.01882636733353138,
        0.018857255578041077,
        0.0187994334846735,
        0.01911947689950466,
        0.01957416534423828,
        0.020397035405039787
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "EleutherAI/gpt-j-6b",
            "cache_dir": "./cache/",
            "tokenizer": "EleutherAI/gpt-j-6b",
            "data_dir": "data/analogies/gpt6b/",
            "importance_results_dir": "rationalization_results/analogies/gpt6b_norm",
            "device": "cuda",
            "rationalization_config": "config/eva_norm.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/gpt6b_norm",
            "loglevel": 20
        },
        "time_elapsed": 0.12967205047607422
    }
}