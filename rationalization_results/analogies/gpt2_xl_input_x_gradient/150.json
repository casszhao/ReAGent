{
    "$schema": "../docs/rationalization.schema.json",
    "id": 150,
    "input-text": [
        "I",
        " had",
        " never",
        " been",
        " friends",
        " with",
        " any",
        " English",
        " people",
        " before",
        ".",
        " (",
        "The",
        " funn",
        "iest",
        " thing",
        " happened",
        " to",
        " me",
        " the",
        " other",
        " day",
        ",",
        " but",
        " that",
        "'s",
        " a",
        " story",
        " for",
        " another",
        " time",
        ").",
        " In",
        " fact",
        ",",
        " I",
        " had",
        " never",
        " even",
        " been",
        " to"
    ],
    "input-tokens": [
        40,
        550,
        1239,
        587,
        2460,
        351,
        597,
        3594,
        661,
        878,
        13,
        357,
        464,
        36090,
        6386,
        1517,
        3022,
        284,
        502,
        262,
        584,
        1110,
        11,
        475,
        326,
        338,
        257,
        1621,
        329,
        1194,
        640,
        737,
        554,
        1109,
        11,
        314,
        550,
        1239,
        772,
        587,
        284
    ],
    "target-text": " England",
    "target-token": 4492,
    "rational-size": 5,
    "rational-positions": [
        7,
        4,
        0,
        2,
        6
    ],
    "rational-text": [
        " English",
        " friends",
        "I",
        " never",
        " any"
    ],
    "rational-tokens": [
        3594,
        2460,
        40,
        1239,
        597
    ],
    "importance-scores": [
        0.09821970015764236,
        0.04294970631599426,
        0.06446758657693863,
        0.04104870185256004,
        0.11196105182170868,
        0.023929955437779427,
        0.045873671770095825,
        0.2269020676612854,
        0.03334851190447807,
        0.009866145439445972,
        0.006909950170665979,
        0.009349084459245205,
        0.007453395053744316,
        0.03930173069238663,
        0.020026857033371925,
        0.007002452854067087,
        0.01303221844136715,
        0.002178067108616233,
        0.006451127119362354,
        0.0024430747143924236,
        0.005609521642327309,
        0.013539849780499935,
        0.0027709784917533398,
        0.0038296084385365248,
        0.0028210515156388283,
        0.0035667174961417913,
        0.002674391493201256,
        0.009357503615319729,
        0.002641913713887334,
        0.006403553299605846,
        0.005259248428046703,
        0.016486603766679764,
        0.007355717942118645,
        0.016797104850411415,
        0.0036807383876293898,
        0.006535403896123171,
        0.010157729499042034,
        0.01829465851187706,
        0.017335956916213036,
        0.017991265282034874,
        0.014175410382449627
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "gpt2-xl",
            "cache_dir": "cache/",
            "tokenizer": "gpt2-xl",
            "data_dir": "data/analogies/gpt2_xl/",
            "importance_results_dir": "rationalization_results/analogies/gpt2_xl_input_x_gradient",
            "device": "cuda",
            "rationalization_config": "config/eva_input_x_gradient.json",
            "input_num_ratio": 1,
            "logfolder": "logs/analogies/gpt2_xl_input_x_gradient",
            "loglevel": 20
        },
        "time_elapsed": 0.09396791458129883
    }
}