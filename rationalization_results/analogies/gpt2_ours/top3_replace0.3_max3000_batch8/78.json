{
    "$schema": "../docs/rationalization.schema.json",
    "id": 78,
    "input-text": [
        "I",
        " initially",
        " invited",
        " my",
        " father",
        ",",
        " who",
        " gladly",
        " accepted",
        " my",
        " invitation",
        ".",
        " (",
        "My",
        " favorite",
        " song",
        " just",
        " came",
        " on",
        ",",
        " so",
        " I",
        " was",
        " able",
        " to",
        " relax",
        ").",
        " When",
        " I",
        " learned",
        " that",
        " women",
        " were",
        " allowed",
        ",",
        " I",
        " went",
        " ahead",
        " and",
        " also",
        " invited",
        " my"
    ],
    "input-tokens": [
        40,
        7317,
        9392,
        616,
        2988,
        11,
        508,
        35092,
        6292,
        616,
        17023,
        13,
        357,
        3666,
        4004,
        3496,
        655,
        1625,
        319,
        11,
        523,
        314,
        373,
        1498,
        284,
        8960,
        737,
        1649,
        314,
        4499,
        326,
        1466,
        547,
        3142,
        11,
        314,
        1816,
        4058,
        290,
        635,
        9392,
        616
    ],
    "target-text": " mother",
    "target-token": 2802,
    "rational-size": 19,
    "rational-positions": [
        0,
        2,
        3,
        4,
        7,
        8,
        10,
        12,
        14,
        16,
        20,
        23,
        26,
        29,
        30,
        31,
        32,
        39,
        41
    ],
    "rational-text": [
        "I",
        " invited",
        " my",
        " father",
        " gladly",
        " accepted",
        " invitation",
        " (",
        " favorite",
        " just",
        " so",
        " able",
        ").",
        " learned",
        " that",
        " women",
        " were",
        " also",
        " my"
    ],
    "rational-tokens": [
        40,
        9392,
        616,
        2988,
        35092,
        6292,
        17023,
        357,
        4004,
        655,
        523,
        1498,
        737,
        4499,
        326,
        1466,
        547,
        635,
        616
    ],
    "importance-scores": [
        0.017628224566578865,
        0.021109050139784813,
        0.012228437699377537,
        0.021168045699596405,
        0.06068204343318939,
        0.017903786152601242,
        0.00807188544422388,
        0.042722441256046295,
        0.025925159454345703,
        0.010824943892657757,
        0.0701475739479065,
        0.012368552386760712,
        0.03593125939369202,
        0.021705452352762222,
        0.014415351673960686,
        0.018245402723550797,
        0.056618884205818176,
        0.02799142524600029,
        0.019660798832774162,
        0.014289513230323792,
        0.02282189577817917,
        0.015632057562470436,
        0.03212440758943558,
        0.019123662263154984,
        0.008617098443210125,
        0.007016942836344242,
        0.013511271215975285,
        0.008040262386202812,
        0.011009126901626587,
        0.021008547395467758,
        0.028455272316932678,
        0.013575680553913116,
        0.020544663071632385,
        0.00966864638030529,
        0.013182868249714375,
        0.009475354105234146,
        0.014851560816168785,
        0.020720696076750755,
        0.018760398030281067,
        0.0426417738199234,
        0.020129727199673653,
        0.09944983571767807
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "gpt2-medium",
            "cache_dir": "cache/",
            "tokenizer": "gpt2-medium",
            "data_dir": "data/analogies/gpt2/",
            "importance_results_dir": "rationalization_results/analogies/gpt2_ours/top3_replace0.3_max3000_batch8",
            "device": "cuda",
            "rationalization_config": "config/gpt2/top3_replace0.3_max3000_batch8.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/gpt2_ours/top3_replace0.3_max3000_batch8",
            "loglevel": 20
        },
        "time_elapsed": 10.528484344482422,
        "separate_rational": [
            [
                " invitation",
                " was",
                " just",
                " my",
                " that",
                " my",
                " father",
                " favorite"
            ],
            [
                " gladly",
                " invitation",
                " (",
                " ahead",
                " father",
                ").",
                " women",
                " so"
            ],
            [
                " learned",
                " song",
                " that",
                " and",
                " my",
                " invited",
                " favorite",
                " father"
            ],
            [
                " just",
                " also",
                " initially",
                " were",
                " (",
                " able",
                " father",
                " I"
            ],
            [
                " my",
                " father",
                " so",
                ",",
                " I",
                " learned",
                " gladly",
                "I"
            ],
            [
                ",",
                " my",
                " father",
                " on",
                " were",
                " able",
                " my",
                " invited"
            ],
            [
                " father",
                ".",
                ",",
                ").",
                " my",
                " accepted",
                "I",
                " also"
            ],
            [
                " my",
                " came",
                " accepted",
                "My",
                " went",
                " women",
                " invited",
                " relax"
            ]
        ]
    }
}