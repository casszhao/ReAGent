{
    "$schema": "../docs/rationalization.schema.json",
    "id": 84,
    "input-text": [
        "I",
        " knew",
        " it",
        " was",
        " fast",
        ",",
        " but",
        " that",
        "'s",
        " before",
        " I",
        " saw",
        " it",
        " in",
        " person",
        ".",
        " (",
        "Just",
        " then",
        " I",
        " thought",
        " about",
        " my",
        " ex",
        "-",
        "wife",
        ",",
        " but",
        " I",
        " had",
        " to",
        " stop",
        " thinking",
        " about",
        " her",
        ").",
        " When",
        " I",
        " did",
        " end",
        " up",
        " seeing",
        " it",
        " in",
        " person",
        ",",
        " it",
        " was",
        " even"
    ],
    "input-tokens": [
        40,
        2993,
        340,
        373,
        3049,
        11,
        475,
        326,
        338,
        878,
        314,
        2497,
        340,
        287,
        1048,
        13,
        357,
        5703,
        788,
        314,
        1807,
        546,
        616,
        409,
        12,
        22095,
        11,
        475,
        314,
        550,
        284,
        2245,
        3612,
        546,
        607,
        737,
        1649,
        314,
        750,
        886,
        510,
        4379,
        340,
        287,
        1048,
        11,
        340,
        373,
        772
    ],
    "target-text": " faster",
    "target-token": 5443,
    "rational-size": 9,
    "rational-positions": [
        1,
        3,
        4,
        15,
        16,
        17,
        32,
        47,
        48
    ],
    "rational-text": [
        " knew",
        " was",
        " fast",
        ".",
        " (",
        "Just",
        " thinking",
        " was",
        " even"
    ],
    "rational-tokens": [
        2993,
        373,
        3049,
        13,
        357,
        5703,
        3612,
        373,
        772
    ],
    "importance-scores": [
        0.006327834911644459,
        0.006528997328132391,
        0.007432716432958841,
        0.01545649953186512,
        0.387079656124115,
        0.004976796917617321,
        0.007892964407801628,
        0.005242237821221352,
        0.0013203228591009974,
        0.001473248703405261,
        0.002977791940793395,
        0.0032239339780062437,
        0.0020068627782166004,
        0.0037437775172293186,
        0.004325842019170523,
        0.009728509932756424,
        0.006425642408430576,
        0.13632650673389435,
        0.009117988869547844,
        0.002626130823045969,
        0.10293199121952057,
        0.00512696010991931,
        0.001867875806055963,
        0.0062582828104496,
        0.003466380760073662,
        0.010867593809962273,
        0.0010617279913276434,
        0.0027170642279088497,
        0.002492413390427828,
        0.0022879682946950197,
        0.0060310666449368,
        0.005517854355275631,
        0.017369946464896202,
        0.0021008788608014584,
        0.004522145725786686,
        0.002412128495052457,
        0.00475339824333787,
        0.0025132286828011274,
        0.04530758783221245,
        0.0033147758804261684,
        0.0016333386301994324,
        0.004053371958434582,
        0.0015358759555965662,
        0.0026521987747401,
        0.0013717261608690023,
        0.0025324630551040173,
        0.002842482179403305,
        0.10571770370006561,
        0.02050536498427391
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "gpt2-medium",
            "cache_dir": "cache/",
            "tokenizer": "gpt2-medium",
            "data_dir": "data/analogies/gpt2/",
            "importance_results_dir": "rationalization_results/analogies/gpt2_ours/top3_replace0.1_max3000_batch5",
            "device": "cuda",
            "rationalization_config": "config/gpt2/top3_replace0.1_max3000_batch5.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/gpt2_ours/top3_replace0.1_max3000_batch5",
            "loglevel": 20
        },
        "time_elapsed": 6.277353763580322,
        "separate_rational": [
            [
                " thought",
                " was",
                " fast",
                " thinking",
                " was",
                ",",
                " even",
                " that"
            ],
            [
                " fast",
                " even",
                " was",
                " (",
                " her",
                " ex",
                " I",
                " it"
            ],
            [
                " did",
                "wife",
                " then",
                " even",
                " was",
                " but",
                "Just",
                "."
            ],
            [
                " fast",
                " thinking",
                " (",
                " seeing",
                " was",
                " knew",
                " even",
                " my"
            ],
            [
                "Just",
                " was",
                " knew",
                " When",
                ".",
                " (",
                " even",
                " fast"
            ]
        ]
    }
}