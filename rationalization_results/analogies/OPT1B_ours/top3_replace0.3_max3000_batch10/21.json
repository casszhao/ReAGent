{
    "$schema": "../docs/rationalization.schema.json",
    "id": 21,
    "input-text": [
        "</s>",
        "I",
        " knew",
        " it",
        " was",
        " high",
        ",",
        " but",
        " that",
        "'s",
        " before",
        " I",
        " saw",
        " it",
        " in",
        " person",
        ".",
        " (",
        "Just",
        " then",
        " I",
        " thought",
        " about",
        " my",
        " ex",
        "-",
        "wife",
        ",",
        " but",
        " I",
        " had",
        " to",
        " stop",
        " thinking",
        " about",
        " her",
        ").",
        " When",
        " I",
        " did",
        " end",
        " up",
        " seeing",
        " it",
        " in",
        " person",
        ",",
        " it",
        " was",
        " even"
    ],
    "input-tokens": [
        2,
        100,
        1467,
        24,
        21,
        239,
        6,
        53,
        14,
        18,
        137,
        38,
        794,
        24,
        11,
        621,
        4,
        36,
        6785,
        172,
        38,
        802,
        59,
        127,
        1931,
        12,
        12295,
        6,
        53,
        38,
        56,
        7,
        912,
        2053,
        59,
        69,
        322,
        520,
        38,
        222,
        253,
        62,
        1782,
        24,
        11,
        621,
        6,
        24,
        21,
        190
    ],
    "target-text": " higher",
    "target-token": 723,
    "rational-size": 10,
    "rational-positions": [
        2,
        3,
        4,
        5,
        6,
        10,
        12,
        36,
        47,
        49
    ],
    "rational-text": [
        " knew",
        " it",
        " was",
        " high",
        ",",
        " before",
        " saw",
        ").",
        " it",
        " even"
    ],
    "rational-tokens": [
        1467,
        24,
        21,
        239,
        6,
        137,
        794,
        322,
        24,
        190
    ],
    "importance-scores": [
        4.823352743344887e-30,
        2.8877678315625193e-25,
        0.0049309623427689075,
        1.3260517575535722e-28,
        4.3410627143962554e-17,
        0.5714278817176819,
        0.0010345831979066133,
        2.668955599745597e-20,
        3.2134396885597645e-26,
        2.3886589321092666e-13,
        4.4176956537356205e-10,
        7.372112678241863e-28,
        2.3217329100932993e-11,
        1.7109967629956553e-20,
        2.2082031748306853e-22,
        6.898555168455367e-23,
        5.4690080174709116e-21,
        3.9979624489801585e-33,
        1.1939062916047441e-42,
        2.906667384372802e-18,
        1.9779061713543808e-26,
        1.401298464324817e-45,
        1.401298464324817e-45,
        3.8577060086614695e-39,
        0.10794395208358765,
        3.2618878429803854e-28,
        1.8961030609320665e-33,
        1.5913422116447615e-19,
        7.146941000810213e-33,
        2.576651247920836e-08,
        3.578413273782461e-26,
        1.3802836042460212e-34,
        3.680577725171261e-25,
        2.516526775244162e-35,
        2.6086679831592855e-37,
        1.4004426674001628e-29,
        7.157787536016258e-07,
        1.064892195235588e-26,
        3.6079631036273208e-12,
        1.1240779791714313e-25,
        1.2812657246286108e-07,
        2.1506233075637345e-35,
        3.9565696706889315e-15,
        2.562606460894295e-30,
        4.600829051071287e-09,
        1.556607534455272e-36,
        2.450921807192477e-24,
        0.17178694903850555,
        3.0577508339459874e-22,
        0.1428748220205307
    ],
    "comments": {
        "created-by": "run_analogies.py",
        "args": {
            "model": "facebook/opt-1.3b",
            "cache_dir": "cache/",
            "tokenizer": "facebook/opt-1.3b",
            "data_dir": "data/analogies/OPT1B",
            "importance_results_dir": "rationalization_results/analogies/OPT1B_ours/top3_replace0.3_max3000_batch10",
            "device": "cuda",
            "rationalization_config": "config//top3_replace0.3_max3000_batch10.json",
            "input_num_ratio": 1.0,
            "logfolder": "logs/analogies/OPT1B_ours/top3_replace0.3_max3000_batch10",
            "loglevel": 20
        },
        "time_elapsed": 662.4627552032471,
        "separate_rational": [
            [
                " ex",
                " it",
                " knew",
                ",",
                " even"
            ],
            [
                " high",
                " even",
                " stop",
                "-",
                " ("
            ],
            [
                " even",
                " was",
                " it",
                " in",
                "wife"
            ],
            [
                " was",
                " saw",
                " high",
                " it",
                " before"
            ],
            [
                " it",
                " knew",
                " high",
                " even",
                ","
            ],
            [
                " high",
                " saw",
                " was",
                " even",
                " that"
            ],
            [
                ",",
                " I",
                " was",
                " thought",
                " high"
            ],
            [
                " it",
                " even",
                " was",
                ").",
                " high"
            ],
            [
                " high",
                " even",
                ").",
                " seeing",
                "</s>"
            ],
            [
                " high",
                ").",
                " before",
                " was",
                " even"
            ]
        ]
    }
}